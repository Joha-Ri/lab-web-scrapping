{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq7Fx0T_DPsE"
   },
   "source": [
    "# Web Scrapping lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3n7CJfCD2pK"
   },
   "source": [
    "In this lab you will scrappe this [website](https://books.toscrape.com/) of books.\n",
    "\n",
    "You have to create a Pandas DataFrame with all the books listed in the page. Each row of the DataFrame should contain information of each book. In particular, the DataFrmae must contain:\n",
    "\n",
    "* category\n",
    "* title\n",
    "* price\n",
    "* stock availability\n",
    "* star rating (number of stars)\n",
    "* description\n",
    "* UPC\n",
    "\n",
    "Happy scrapping!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaqLnJRLBqMS"
   },
   "source": [
    "# Server verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNXuRli_BvJp"
   },
   "source": [
    "Load the needed libraries, and make sure thar you can obtain the correct status code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szKOZm99Frlf",
    "outputId": "184b2f54-7eaa-4d31-b66f-f3f8311e80e6"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSrTPTKnCD-N"
   },
   "source": [
    "# Book categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yu5FjaMECISF"
   },
   "source": [
    "Create the code to collect the **relative urls** from the left panel to obtain a list with all the book categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m url_lab \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://books.toscrape.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[43murl\u001b[49m)\n\u001b[0;32m      3\u001b[0m html_obtenido \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[1;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "url_lab = \"https://books.toscrape.com/\"\n",
    "response = requests.get(url)\n",
    "html_obtenido = response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_obtenido, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the code to collect the relative urls from the left panel to obtain a list with all the book categories.\n",
    "\n",
    "cat_section = soup.find('ul', class_='nav-list')\n",
    "cat_links = categories_section.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_urls = []\n",
    "for link in cat_links:\n",
    "    href = link.get('href')\n",
    "    if href:\n",
    "       category_urls.append(href.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in category_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y12krHNrGPsu",
    "outputId": "8e1a4907-1b82-4f2d-f8a9-c7c10b6e6bed"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAq9izU8Cpyx"
   },
   "source": [
    "# Books in a given category\n",
    "\n",
    "Use. web scrapping and list comprehension to obtain the **absolute** url of each book to be scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gC6uP76bHwNv"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "base_url = \"http://books.toscrape.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLIh0a_LDJMo"
   },
   "source": [
    "# Book details\n",
    "\n",
    "Create a Python function that given a book_url as an input returns a dictionary with the following structure:\n",
    "\n",
    "```Python\n",
    "{\"Title\": title, \"Price\": price, \"Availability\": availability, \"Rating\": rating, \"Description\": description, \"UPC\": upc}\n",
    "```\n",
    "\n",
    "where `description` should contain the book's summary given in the Product description, and the values are the book's associated information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-uC7hz1LxCd"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def extract_book_details(book_url):\n",
    "    response = requests.get(book_url)  # Send a GET request to the book URL\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrct the book \"title\"\n",
    "title = soup.find('h1').get_text()\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the book price\n",
    "price = soup.find('p', class_='price_color').get_text()\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# availability\n",
    "availability = soup.find('p', class_='instock availability').get_text(strip=True)\n",
    "availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating information\n",
    "rating_inf = soup.find('p', class_='star-rating')\n",
    "rating = rating_inf['class'][1] if rating_inf else \"No rating\"\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description\n",
    "description_element = soup.find('meta', {'name': 'description'})\n",
    "description = description_element['content'].strip() if description_element else \"No description available.\"\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPC universal product code\n",
    "upc_cat = soup.find('th', string='UPC')\n",
    "upc = upc_cat.find_next_sibling('td').get_text()if upc_cat else \"No UPC available\"\n",
    "upc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvSqhX4UDxbb"
   },
   "source": [
    "# Collect and store all the information from the books in a Pandas DataFrame\n",
    "\n",
    "Start with the following dictionary:\n",
    "\n",
    "```python\n",
    "books_dict = {\"Title\": [], \"Price\": [], \"Availability\": [], \"Rating\": [], \"Description\": [], \"UPC\": [], \"Category\": [] }\n",
    "```\n",
    "\n",
    "Then, iterate over all the categories and all the books in a given category to collect any book information using the previous function. Fill the previous dictionary with the information about each book.\n",
    "\n",
    "Show the first five rows of the previous final Pandas DataFrame.\n",
    "\n",
    "Tip: You can use the function `tqdm` from the library `tqdm` to show a progress bar if in iterable of a for loop as shown below :wink: :\n",
    "\n",
    "```python\n",
    "from tqdm import tqdm\n",
    "\n",
    "for elem in tqdm(iterable):\n",
    "    # some code\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "apeImoCxStA5",
    "outputId": "20d2d37c-5cbe-4062-e407-80f77955a8d3"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://books.toscrape.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_urls():\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    categories = soup.find('ul', class_='nav-list').find('ul').find_all('a')\n",
    "    category_urls = {category.get_text(strip=True): urljoin(base_url, category['href']) for category in categories}\n",
    "    return category_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_urls(category_url):\n",
    "    book_urls = []\n",
    "    while category_url:\n",
    "        response = requests.get(category_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        books = soup.find_all('h3')\n",
    "        book_urls += [urljoin(base_url, book.find('a')['href']) for book in books]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Find the next page URL if it exists\n",
    "next_page = soup.find('li', class_='next')\n",
    "category_url = urljoin(base_url, next_page.find('a')['href']) if next_page else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract book details\n",
    "def extract_book_details(book_url):\n",
    "    response = requests.get(book_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract details\n",
    "title = soup.find('h1').get_text()\n",
    "price = soup.find('p', class_='price_color').get_text()\n",
    "availability = soup.find('p', class_='instock availability').get_text(strip=True)\n",
    "rating_element = soup.find('p', class_='star-rating')\n",
    "rating = rating_element['class'][1] if rating_element else \"No rating\"\n",
    "description_element = soup.find('meta', {'name': 'description'})\n",
    "description = description_element['content'].strip() if description_element else \"No description available.\"\n",
    "upc_element = soup.find('th', string='UPC')\n",
    "upc = upc_element.find_next_sibling('td').get_text() if upc_element else \"No UPC available.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each category and each book within that category\n",
    "category_urls = get_category_urls()\n",
    "\n",
    "for category_name, category_url in tqdm(category_urls.items(), desc=\"Processing categories\"):\n",
    "    book_urls = get_book_urls(category_url)\n",
    "    for book_url in tqdm(book_urls, desc=f\"Processing books in {category_name}\", leave=False):\n",
    "        book_details = extract_book_details(book_url)\n",
    "        # Append book details to the dictionary\n",
    "        for key, value in book_details.items():\n",
    "            books_dict[key].append(value)\n",
    "        books_dict[\"Category\"].append(category_name)\n",
    "books_df = pd.DataFrame(books_dict)\n",
    "print(books_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
